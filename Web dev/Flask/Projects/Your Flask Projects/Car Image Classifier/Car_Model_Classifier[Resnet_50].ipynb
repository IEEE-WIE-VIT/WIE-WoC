{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car Model Classifier[Resnet 50].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uksayA2MDXmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ced96b04-deee-464e-dd57-addbbbad7599"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xatF0XpzD0oD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGZg-vGpE6dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/My Drive/Car Model Classifier/Datasets/Train'\n",
        "valid_path = '/content/drive/My Drive/Car Model Classifier/Datasets/test'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL6QmAvSFKch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ab21093b-4747-4ead-c306-a3d42d070e31"
      },
      "source": [
        "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
        "# Here we will be using imagenet weights\n",
        "\n",
        "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsWOVoJoFNOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# don't train existing weights\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJId78OEFVdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a365f03f-b046-4fbf-ddb7-3dbef0dcd5c5"
      },
      "source": [
        "  # useful for getting number of output classes\n",
        "folders = glob('/content/drive/My Drive/Car Model Classifier/Datasets/Train/*')\n",
        "folders"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Car Model Classifier/Datasets/Train/audi',\n",
              " '/content/drive/My Drive/Car Model Classifier/Datasets/Train/mercedes',\n",
              " '/content/drive/My Drive/Car Model Classifier/Datasets/Train/lamborghini']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_HAD4I7FhKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(resnet.output)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQWnP_JhFxdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=resnet.input, outputs=prediction)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnUI9VTbF3ZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bd456ad-989f-45ec-eeae-4f1ad55a6262"
      },
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,888,771\n",
            "Trainable params: 301,059\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfwa9_VAF6p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj3EoIQMF8zW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InaOrBNrF_3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45ecd662-2d40-4549-abdb-81f135db304e"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Car Model Classifier/Datasets/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 90 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owAERq9iGDbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24744804-6120-4fc9-9349-618ab4731974"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Car Model Classifier/Datasets/Test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 58 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y3jDGBYGMR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cd1fd62-d909-41b4-8815-f08204cfc2d9"
      },
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=100,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-b195b6f1aa8b>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 597ms/step - loss: 6.8157 - accuracy: 0.3333 - val_loss: 4.8586 - val_accuracy: 0.5172\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 4.8677 - accuracy: 0.3889 - val_loss: 7.9464 - val_accuracy: 0.1552\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 5.0276 - accuracy: 0.3778 - val_loss: 5.7604 - val_accuracy: 0.3276\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 2.9957 - accuracy: 0.3889 - val_loss: 2.9508 - val_accuracy: 0.5172\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 2.7678 - accuracy: 0.4333 - val_loss: 3.2934 - val_accuracy: 0.1724\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 1.4826 - accuracy: 0.5222 - val_loss: 1.8187 - val_accuracy: 0.4483\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 359ms/step - loss: 1.7379 - accuracy: 0.4889 - val_loss: 1.0784 - val_accuracy: 0.6207\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 1.3806 - accuracy: 0.5000 - val_loss: 1.6756 - val_accuracy: 0.2759\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 1.1281 - accuracy: 0.4889 - val_loss: 1.1481 - val_accuracy: 0.6034\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.7991 - accuracy: 0.6222 - val_loss: 1.3723 - val_accuracy: 0.3793\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 0.8472 - accuracy: 0.6222 - val_loss: 0.9285 - val_accuracy: 0.6379\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.7432 - accuracy: 0.6556 - val_loss: 0.8410 - val_accuracy: 0.6897\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.7427 - accuracy: 0.6556 - val_loss: 1.4577 - val_accuracy: 0.4138\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.7563 - accuracy: 0.6667 - val_loss: 0.9981 - val_accuracy: 0.6552\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.7243 - accuracy: 0.6667 - val_loss: 1.0158 - val_accuracy: 0.5862\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.6749 - accuracy: 0.6778 - val_loss: 0.8005 - val_accuracy: 0.7241\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.6211 - accuracy: 0.7111 - val_loss: 0.8260 - val_accuracy: 0.7586\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 1.0279 - val_accuracy: 0.6207\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.4827 - accuracy: 0.8111 - val_loss: 0.8982 - val_accuracy: 0.7241\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.6078 - accuracy: 0.7000 - val_loss: 0.8302 - val_accuracy: 0.7241\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.4135 - accuracy: 0.8444 - val_loss: 1.0293 - val_accuracy: 0.6034\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 346ms/step - loss: 0.4799 - accuracy: 0.7667 - val_loss: 0.8578 - val_accuracy: 0.6897\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.3991 - accuracy: 0.8111 - val_loss: 1.1045 - val_accuracy: 0.6034\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 354ms/step - loss: 0.4225 - accuracy: 0.8556 - val_loss: 0.8435 - val_accuracy: 0.7241\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.4518 - accuracy: 0.8222 - val_loss: 0.8960 - val_accuracy: 0.7069\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 0.4106 - accuracy: 0.8111 - val_loss: 0.8711 - val_accuracy: 0.6724\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 0.3525 - accuracy: 0.8667 - val_loss: 0.8339 - val_accuracy: 0.7759\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 0.3949 - accuracy: 0.8556 - val_loss: 0.8743 - val_accuracy: 0.6724\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 357ms/step - loss: 0.3973 - accuracy: 0.8222 - val_loss: 0.8181 - val_accuracy: 0.7586\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 0.3230 - accuracy: 0.9222 - val_loss: 0.8633 - val_accuracy: 0.7586\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 353ms/step - loss: 0.3307 - accuracy: 0.8778 - val_loss: 0.8113 - val_accuracy: 0.7241\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 0.3067 - accuracy: 0.9222 - val_loss: 0.8527 - val_accuracy: 0.7414\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.3553 - accuracy: 0.8444 - val_loss: 0.8383 - val_accuracy: 0.7586\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 0.3214 - accuracy: 0.9222 - val_loss: 0.8365 - val_accuracy: 0.6897\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.3159 - accuracy: 0.8667 - val_loss: 0.8651 - val_accuracy: 0.7414\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.3078 - accuracy: 0.8778 - val_loss: 0.8362 - val_accuracy: 0.7241\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.2914 - accuracy: 0.9000 - val_loss: 0.8139 - val_accuracy: 0.7241\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.2559 - accuracy: 0.9667 - val_loss: 0.8046 - val_accuracy: 0.7414\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.2631 - accuracy: 0.9111 - val_loss: 0.8143 - val_accuracy: 0.7414\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 1s 338ms/step - loss: 0.2631 - accuracy: 0.9222 - val_loss: 0.8028 - val_accuracy: 0.7414\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.3208 - accuracy: 0.8778 - val_loss: 0.8545 - val_accuracy: 0.7241\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.3625 - accuracy: 0.8222 - val_loss: 0.9872 - val_accuracy: 0.6724\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.3003 - accuracy: 0.9000 - val_loss: 0.8423 - val_accuracy: 0.7586\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 1s 359ms/step - loss: 0.2715 - accuracy: 0.8889 - val_loss: 0.9421 - val_accuracy: 0.6897\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 0.2941 - accuracy: 0.9333 - val_loss: 0.8495 - val_accuracy: 0.7069\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.2760 - accuracy: 0.8778 - val_loss: 0.9218 - val_accuracy: 0.6897\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.3008 - accuracy: 0.9000 - val_loss: 0.8816 - val_accuracy: 0.7069\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 1s 366ms/step - loss: 0.2766 - accuracy: 0.9444 - val_loss: 0.8745 - val_accuracy: 0.7931\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.2186 - accuracy: 0.9444 - val_loss: 0.9737 - val_accuracy: 0.6379\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.4056 - accuracy: 0.8333 - val_loss: 1.2692 - val_accuracy: 0.5517\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 1s 372ms/step - loss: 0.4344 - accuracy: 0.8111 - val_loss: 1.1077 - val_accuracy: 0.6207\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.4051 - accuracy: 0.8667 - val_loss: 1.1817 - val_accuracy: 0.5862\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.3887 - accuracy: 0.8111 - val_loss: 1.1333 - val_accuracy: 0.6897\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.4961 - accuracy: 0.7889 - val_loss: 1.2236 - val_accuracy: 0.5862\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.3254 - accuracy: 0.8778 - val_loss: 0.9589 - val_accuracy: 0.7241\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.3062 - accuracy: 0.8778 - val_loss: 1.1872 - val_accuracy: 0.6379\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.2337 - accuracy: 0.9444 - val_loss: 0.9336 - val_accuracy: 0.7069\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 0.2900 - accuracy: 0.8556 - val_loss: 0.9796 - val_accuracy: 0.7069\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 1s 366ms/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.8481 - val_accuracy: 0.7586\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.2019 - accuracy: 0.9444 - val_loss: 0.8399 - val_accuracy: 0.7931\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.1909 - accuracy: 0.9333 - val_loss: 0.9020 - val_accuracy: 0.7414\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.1764 - accuracy: 0.9778 - val_loss: 0.8610 - val_accuracy: 0.7931\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.2341 - accuracy: 0.9000 - val_loss: 0.8445 - val_accuracy: 0.7586\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.1870 - accuracy: 0.9556 - val_loss: 0.8829 - val_accuracy: 0.7931\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 1s 346ms/step - loss: 0.1714 - accuracy: 0.9889 - val_loss: 0.8356 - val_accuracy: 0.7586\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.1418 - accuracy: 0.9889 - val_loss: 0.8983 - val_accuracy: 0.7931\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 0.1554 - accuracy: 0.9778 - val_loss: 0.8320 - val_accuracy: 0.7759\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.1440 - accuracy: 0.9556 - val_loss: 0.8282 - val_accuracy: 0.7759\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.1516 - accuracy: 0.9778 - val_loss: 0.8804 - val_accuracy: 0.7414\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.1831 - accuracy: 0.9444 - val_loss: 0.8929 - val_accuracy: 0.8103\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.1938 - accuracy: 0.9556 - val_loss: 0.8473 - val_accuracy: 0.7586\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.1863 - accuracy: 0.9667 - val_loss: 0.8417 - val_accuracy: 0.7759\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.1408 - accuracy: 0.9889 - val_loss: 0.8544 - val_accuracy: 0.7586\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.1481 - accuracy: 0.9667 - val_loss: 0.8592 - val_accuracy: 0.7586\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 1s 356ms/step - loss: 0.1837 - accuracy: 0.9222 - val_loss: 0.8482 - val_accuracy: 0.7759\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.2012 - accuracy: 0.9556 - val_loss: 0.8505 - val_accuracy: 0.7586\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.1723 - accuracy: 0.9556 - val_loss: 0.8370 - val_accuracy: 0.7759\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 1s 355ms/step - loss: 0.1328 - accuracy: 0.9889 - val_loss: 0.8685 - val_accuracy: 0.8103\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 368ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.8692 - val_accuracy: 0.7414\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.1562 - accuracy: 0.9556 - val_loss: 0.8477 - val_accuracy: 0.7931\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 0.1802 - accuracy: 0.9444 - val_loss: 0.8589 - val_accuracy: 0.7586\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.2026 - accuracy: 0.9111 - val_loss: 0.9529 - val_accuracy: 0.7759\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 1s 358ms/step - loss: 0.1945 - accuracy: 0.9222 - val_loss: 0.8347 - val_accuracy: 0.7759\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.1791 - accuracy: 0.9222 - val_loss: 0.8491 - val_accuracy: 0.8103\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.7414\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.1356 - accuracy: 0.9889 - val_loss: 0.8579 - val_accuracy: 0.7759\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.7931\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.1203 - accuracy: 0.9889 - val_loss: 0.8432 - val_accuracy: 0.7759\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 1s 346ms/step - loss: 0.1375 - accuracy: 0.9778 - val_loss: 0.8863 - val_accuracy: 0.7931\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.1353 - accuracy: 0.9778 - val_loss: 0.8618 - val_accuracy: 0.7586\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 1s 338ms/step - loss: 0.1150 - accuracy: 0.9889 - val_loss: 0.9008 - val_accuracy: 0.7931\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.1628 - accuracy: 0.9667 - val_loss: 0.8596 - val_accuracy: 0.7759\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 1s 338ms/step - loss: 0.1614 - accuracy: 0.9667 - val_loss: 0.8593 - val_accuracy: 0.7759\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.1133 - accuracy: 0.9889 - val_loss: 0.8504 - val_accuracy: 0.7759\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 0.8570 - val_accuracy: 0.7759\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.8746 - val_accuracy: 0.7586\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.1193 - accuracy: 0.9889 - val_loss: 0.8449 - val_accuracy: 0.7759\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.1125 - accuracy: 0.9778 - val_loss: 0.8415 - val_accuracy: 0.7759\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.7759\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.1338 - accuracy: 0.9889 - val_loss: 0.8474 - val_accuracy: 0.7759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9LbL0QvHTgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save it as a h5 file\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/My Drive/Car Model Classifier/model_resnet50.h5')"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}